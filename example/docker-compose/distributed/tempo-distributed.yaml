search_enabled: true
metrics_generator_enabled: true

server:
  http_listen_port: 3200

distributor:
  receivers:                           # this configuration will listen on all ports and protocols that tempo is capable of.
    jaeger:                            # the receives all come from the OpenTelemetry collector.  more configuration information can
      protocols:                       # be found there: https://github.com/open-telemetry/opentelemetry-collector/tree/main/receiver
        thrift_http:                   #
        grpc:                          # for a production deployment you should only enable the receivers you need!
        thrift_binary:
        thrift_compact:
    zipkin:
    otlp:
      protocols:
        http:
        grpc:
    opencensus:

ingester:
  trace_idle_period: 10s               # the length of time after a trace has not received spans to consider it complete and flush it
  max_block_bytes: 1_000_000           # cut the head block when it hits this size or ...
  max_block_duration: 5m               #   this much time passes
  lifecycler:
    ring:
      replication_factor: 3

memberlist:
  abort_if_cluster_join_fails: false
  bind_port: 7946
  join_members:
  - ingester-0:7946
  - ingester-1:7946
  - ingester-2:7946

compactor:
  compaction:
    block_retention: 1h
    compacted_block_retention: 10m

query_frontend:
    query_shards: 2

querier:
  frontend_worker:
    frontend_address: query-frontend:9095

metrics_generator:
  remote_write:
    enabled: true
    client:
      url: http://prometheus:9090/api/v1/write

storage:
  trace:
    backend: s3
    s3:
      bucket: tempo
      endpoint: minio:9000
      access_key: tempo
      secret_key: supersecret
      insecure: true
    wal:
      path: /tmp/tempo/wal             # where to store the the wal locally
      encoding: snappy                 # wal encoding/compression.  options: none, gzip, lz4-64k, lz4-256k, lz4-1M, lz4, snappy, zstd, s2
    local:
      path: /tmp/tempo/blocks
    pool:
      max_workers: 100                 # worker pool determines the number of parallel requests to the object store backend
      queue_depth: 10000

overrides:
  metrics_generator_processors: ['service-graphs', 'span-metrics']
