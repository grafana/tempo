---
title: Service graphs
---

# Service graphs

<span style="background-color:#f3f973;">This is an experimental feature. See below for more information on how to enable.</span>

A service graph is a visual representation of the interrelationships between various services.
Service graphs help to understand the structure of a distributed system,
and the connections and dependencies between its components.

Service graphs are great for:

- **Infer the topology of a distributed system.**
  As distributed systems grow, they become more complex.
  Service graphs can help you understand the structure of the system.
- **Provide a high level overview of the health of your system.**
  Service graphs show error rates, latencies, among other relevant data.
- **Provide an historic view of a system’s topology.**
  Distributed systems change very frequently,
  and service graphs offer a way of seeing how these systems have evolved over time.

<p align="center"><img src="../service-graphs.png" alt="Service graphs example"></p>

## How they work

Service graphs are generated by the Grafana Agent.
The Agent will process traces and generate service graphs in the form of prometheus metrics.
The generated metrics represent edges between nodes in the graph. Nodes are represented by `client` and `server` labels.

```
  tempo_service_graph_request_total{client="app", server="db"} 20
```

<p align="center"><img src="../service-graphs-agent-architecture.png" alt="Service graphs architecture"></p>

Service graphs works by inspecting spans and looking for the tag [`span.kind`](https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/trace/api.md#spankind).
If it finds the span kind to be client or server, it stores the request in a local in-memory store.

That request waits until its corresponding client or server pair span is processed or until the maximum waiting time has passed.
When either of those conditions is reached, the request is processed and removed from the local store.
If the request is complete by that time, it'll be recorded as an edge in the graph.

To generate service graphs using a multi-agent deployment, use the load balancing feature.
This will group all spans of a trace in the same agent.
To configure load balancing check the `load_balancing` section of the [Agent configuration](https://grafana.com/docs/agent/latest/configuration/traces-config/).

## Quickstart

Service graphs are generated in the Grafana Agent and pushed to a prometheus compatible backend.
Then, they can be represented in Grafana as a graph.
Thus, you will need those components to fully use service graphs.

### Grafana Agent

To start using service graphs, enable the feature in the Grafana Agent config.

```
traces:
  configs:
    - name: default
      ...
      service_graphs:
        enabled: true
```

To see all the available config options, refer to the [configuration reference](https://grafana.com/docs/agent/latest/configuration/traces-config/).

Metrics are registered in the Agent's default registerer.
Therefore, they are exposed at `/metrics` in the Agent's server port.
One option is to use the Agent self-scrape capabilities to export the metrics to a prometheus compatible backend.

```
server:
  http_listen_port: 12345
metrics:
  configs:
    - name: default
      scrape_configs:
        - job_name: local_scrape
          static_configs:
            - targets: ['127.0.0.1:12345']
      remote_write:
        - url: <remote_write>
```

### Grafana

Service graphs is hidden under the feature flag `tempoServiceGraphs`.

To run this feature:
1. Run Grafana 8.2 or the latest pre-release and enable the `tempoSearch` [feature toggle](https://grafana.com/docs/grafana/latest/packages_api/data/featuretoggles/#temposervicegraph-property).
2. Configure a Tempo datasource's 'Service Graphs' section by linking to the prometheus backend where metrics are being sent.

Example provisioned datasource config for service graphs:

```
apiVersion: 1
datasources:
  # Prometheus backend where metrics are sent
  - name: Prometheus
    type: prometheus
    uid: prometheus
    url: <prometheus-url>
    jsonData:
        httpMethod: GET
    version: 1
  - name: Tempo
    type: tempo
    uid: tempo
    url: <tempo-url>
    jsonData:
      httpMethod: GET
      serviceMap:
        datasourceUid: 'prometheus'
    version: 1
```

## Cardinality

Cardinality can pose a problem when you have lots of services.
There isn't a direct formula or solution to this problem.
But the following guide should help estimate the cardinality that the feature will generate.

### How to estimate the cardinality

The amount of edges depends on the amount of nodes in the system and the direction of the requests between them.
Let’s call this amount hops. Every hop will be a unique combination of client + server labels.

For example:
- a system with 3 nodes `(A, B, C)` of which A only calls B and B only calls C will have 2 hops `(A → B, B → C)`
- a system with 3 nodes `(A, B, C)` that call each other (i.e. all bidirectional links somehow) will have 6 hops `(A → B, B → A, B → C, C → B, A → C, C → A)`

We can’t calculate the amount of hops automatically based upon the nodes,
but it should be a value between `#services - 1` and `#services!`.

If we know the amount of hops in a system, we can calculate the cardinality of the generated service graphs:

```
  service_graph_request_total: #hops
  service_graph_request_failed_total: #hops
  service_graph_request_server_seconds: 3 buckets * #hops
  service_graph_request_client_seconds: 3 buckets * #hops
  service_graph_unpaired_spans_total: #services (absolute worst case)
  service_graph_dropped_spans_total: #services (absolute worst case)
```

Finally, we get the following cardinality estimation:

```
  Sum: 8 * #hops + 2 * #services
```
